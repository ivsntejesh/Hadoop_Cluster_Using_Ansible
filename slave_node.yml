- hosts: 192.168.1.105
  vars_files:
          - var.yml
  tasks:
          - name: copying jdk file
            copy:
                  dest: "/root/"
                  src: "/ansible-ws/task-11.1/jdk-8u171-linux-x64.rpm"

          - name: copying hadoop file
            copy:
                  dest: "/root/"
                  src: "/ansible-ws/task-11.1/hadoop-1.2.1-1.x86_64.rpm"

          - name: installing jdk
            command: "rpm -ivh jdk-8u171-linux-x64.rpm"
            register: x
            ignore_errors: yes

          - name: output of jdk
            debug:
                  var: x.stdout

          - name: installing hadoop
            command: "rpm -ivh hadoop-1.2.1-1.x86_64.rpm --force"
            register: y
            ignore_errors: yes

          - name: output of hasoop download
            debug:
                  var: y.stdout

          - name: removing the directory if already present
            shell: "rm -rf {{ data_dir }}"
            ignore_errors: yes

          - name: copy the hdfs file
            copy:
                  dest: "/etc/hadoop/hdfs-site.xml"
                  src: "/ansible-ws/task-11.1/hdfs-site.xml"

          - name: copy the core file
            copy:
                  dest: "/etc/hadoop/core-site.xml"
                  src: "/ansible-ws/task-11.1/core-site.xml"

          - name: update the core file
            blockinfile:
                  path: "/etc/hadoop/hdfs-site.xml"
                  insertafter: <property>
                  block: |
                         <name>{{ data }}</name> 
                         <value>{{ data_dir }}</value>
          - debug:
                  var: groups['namenode']

          - name: update the core file
            blockinfile:
                  path: "/etc/hadoop/core-site.xml"
                  insertafter: </name>
                  block: 
                          <value>hdfs://{{ groups['namenode'][0] }}:9001</value> 
          - name: stopping the datanode if already running
            shell: "hadoop-daemon.sh stop datanode"
            ignore_errors: yes
            register: stop_data

          - name: output of datanode 
            debug:
                   var: stop_data.stdout
          
          - name: starting the datanode
            shell: "hadoop-daemon.sh start datanode"
            register: start_data

          - name: output of servicecstarting datanode
            debug:
                  var: start_data.stdout

          - name: running jps
            command: "jps"
            register: run_jps

          - name: output of jps commandd
            debug:
                  var: run_jps.stdout

          - name: running the report command
            command: "hadoop dfsadmin -report"
            register: report

          - name: output of report
            debug:
                  var: report.stdout
